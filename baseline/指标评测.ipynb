{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding=utf-8\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import datetime\n",
    "import json\n",
    "import sys\n",
    "import time\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the higher scores, the better performance\n",
    "def evaluate_each_phase(predictions, answers):\n",
    "    list_item_degress = []\n",
    "    for user_id in answers:\n",
    "        item_id, item_degree = answers[user_id]\n",
    "        list_item_degress.append(item_degree)\n",
    "    list_item_degress.sort()\n",
    "    median_item_degree = list_item_degress[len(list_item_degress) // 2]\n",
    "\n",
    "    num_cases_full = 0.0\n",
    "    ndcg_50_full = 0.0\n",
    "    ndcg_50_half = 0.0\n",
    "    num_cases_half = 0.0\n",
    "    hitrate_50_full = 0.0\n",
    "    hitrate_50_half = 0.0\n",
    "    for user_id in answers:\n",
    "        item_id, item_degree = answers[user_id]\n",
    "        rank = 0\n",
    "        while rank < 50 and predictions[user_id][rank] != item_id:\n",
    "            rank += 1\n",
    "        num_cases_full += 1.0\n",
    "        if rank < 50:\n",
    "            ndcg_50_full += 1.0 / np.log2(rank + 2.0)\n",
    "            hitrate_50_full += 1.0\n",
    "        if item_degree <= median_item_degree:\n",
    "            num_cases_half += 1.0\n",
    "            if rank < 50:\n",
    "                ndcg_50_half += 1.0 / np.log2(rank + 2.0)\n",
    "                hitrate_50_half += 1.0\n",
    "    ndcg_50_full /= num_cases_full\n",
    "    hitrate_50_full /= num_cases_full\n",
    "    ndcg_50_half /= num_cases_half\n",
    "    hitrate_50_half /= num_cases_half\n",
    "    return np.array([ndcg_50_full, ndcg_50_half,\n",
    "                     hitrate_50_full, hitrate_50_half], dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submit_fname is the path to the file submitted by the participants.\n",
    "# debias_track_answer.csv is the standard answer, which is not released.\n",
    "def evaluate(submit_fname,\n",
    "             answer_fname='debias_track_answer.csv', current_time=None):\n",
    "    schedule_in_unix_time = [\n",
    "        0,  # ........ 1970-01-01 08:00:00 (T=0)\n",
    "        1586534399,  # 2020-04-10 23:59:59 (T=1)\n",
    "        1587139199,  # 2020-04-17 23:59:59 (T=2)\n",
    "        1587743999,  # 2020-04-24 23:59:59 (T=3)\n",
    "        1588348799,  # 2020-05-01 23:59:59 (T=4)\n",
    "        1588953599,  # 2020-05-08 23:59:59 (T=5)\n",
    "        1589558399,  # 2020-05-15 23:59:59 (T=6)\n",
    "        1590163199,  # 2020-05-22 23:59:59 (T=7)\n",
    "        1590767999,  # 2020-05-29 23:59:59 (T=8)\n",
    "        1591372799  # .2020-06-05 23:59:59 (T=9)\n",
    "    ]\n",
    "    assert len(schedule_in_unix_time) == 10\n",
    "\n",
    "    if current_time is None:\n",
    "        current_time = int(time.time())\n",
    "    print('current_time:', current_time)\n",
    "    print('date_time:', datetime.datetime.fromtimestamp(current_time))\n",
    "    current_phase = 0\n",
    "    while (current_phase < 9) and (\n",
    "            current_time > schedule_in_unix_time[current_phase + 1]):\n",
    "        current_phase += 1\n",
    "    print('current_phase:', current_phase)\n",
    "    current_phase = 3\n",
    "    try:\n",
    "        answers = [{} for _ in range(10)]\n",
    "        with open(answer_fname, 'r') as fin:\n",
    "            for line in fin:\n",
    "                line = [int(x) for x in line.split(',')]\n",
    "                phase_id, user_id, item_id, item_degree = line\n",
    "                assert user_id % 11 == phase_id\n",
    "                # exactly one test case for each user_id\n",
    "                answers[phase_id][user_id] = (item_id, item_degree)\n",
    "    except Exception as _:\n",
    "        return 'server-side error: answer file incorrect'\n",
    "\n",
    "    try:\n",
    "        predictions = {}\n",
    "        with open(submit_fname, 'r') as fin:\n",
    "            for line in fin:\n",
    "                line = line.strip()\n",
    "                if line == '':\n",
    "                    continue\n",
    "                line = line.split(',')\n",
    "                user_id = int(line[0])\n",
    "                if user_id in predictions:\n",
    "                    return 'submitted duplicate user_ids'\n",
    "                item_ids = [int(i) for i in line[1:]]\n",
    "                if len(item_ids) != 50:\n",
    "                    return 'each row need have 50 items'\n",
    "                if len(set(item_ids)) != 50:\n",
    "                    return 'each row need have 50 DISTINCT items'\n",
    "                predictions[user_id] = item_ids\n",
    "    except Exception as _:\n",
    "        return 'submission not in correct format'\n",
    "\n",
    "    scores = np.zeros(4, dtype=np.float32)\n",
    "\n",
    "    # The final winning teams will be decided based on phase T=7,8,9 only.\n",
    "    # We thus fix the scores to 1.0 for phase 0,1,2,...,6 at the final stage.\n",
    "    if current_phase >= 7:  # if at the final stage, i.e., T=7,8,9\n",
    "        scores += 7.0  # then fix the scores to 1.0 for phase 0,1,2,...,6\n",
    "    phase_beg = (7 if (current_phase >= 7) else 0)\n",
    "    phase_end = current_phase + 1\n",
    "    for phase_id in range(phase_beg, phase_end):\n",
    "        for user_id in answers[phase_id]:\n",
    "            if user_id not in predictions:\n",
    "                return 'user_id %d of phase %d not in submission' % (user_id, phase_id)\n",
    "        try:\n",
    "            # We sum the scores from all the phases, instead of averaging them.\n",
    "            scores += evaluate_each_phase(predictions, answers[phase_id])\n",
    "        except Exception as _:\n",
    "            return 'error occurred during evaluation'\n",
    "\n",
    "    return {\n",
    "            'score': float(scores[0]),\n",
    "            'ndcg_50_full': float(scores[0]), \n",
    "            'ndcg_50_half': float(scores[1]),\n",
    "            'hitrate_50_full': float(scores[2]),\n",
    "            'hitrate_50_half': float(scores[3])\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FYI. You can create a fake answer file for validation based on this. For example,\n",
    "# you can mask the latest ONE click made by each user in underexpose_test_click-T.csv,\n",
    "# and use those masked clicks to create your own validation set, i.e.,\n",
    "# a fake underexpose_test_qtime_with_answer-T.csv for validation.\n",
    "def _create_answer_file_for_evaluation(answer_fname='debias_track_answer.csv'):\n",
    "    train = '../../../data/kddcup2020/new_underexpose_train/new_underexpose_train_click-%d.csv'\n",
    "    test = '../../../data/kddcup2020/new_underexpose_test/new_underexpose_test_click-%d/new_underexpose_test_click-%d.csv'\n",
    "\n",
    "    # underexpose_test_qtime-T.csv contains only <user_id, item_id>\n",
    "    # underexpose_test_qtime_with_answer-T.csv contains <user_id, item_id, time>\n",
    "    #answer = 'underexpose_test_qtime_with_answer-%d.csv'  # not released\n",
    "    answer = '../../../data/kddcup2020/new_underexpose_test/new_underexpose_test_click-%d/new_underexpose_test_qtime-%d.csv'\n",
    "\n",
    "    item_deg = defaultdict(lambda: 0)\n",
    "    with open(answer_fname, 'w') as fout:\n",
    "        for phase_id in range(10):\n",
    "            with open(train % phase_id) as fin:\n",
    "                for line in fin:\n",
    "                    user_id, item_id, timestamp = line.split(',')\n",
    "                    user_id, item_id, timestamp = (\n",
    "                        int(user_id), int(item_id), float(timestamp))\n",
    "                    item_deg[item_id] += 1\n",
    "            with open(test % (phase_id, phase_id)) as fin:\n",
    "                for line in fin:\n",
    "                    user_id, item_id, timestamp = line.split(',')\n",
    "                    user_id, item_id, timestamp = (\n",
    "                        int(user_id), int(item_id), float(timestamp))\n",
    "                    item_deg[item_id] += 1\n",
    "            with open(answer % (phase_id, phase_id)) as fin:\n",
    "                for line in fin:\n",
    "                    user_id, item_id, timestamp = line.split(',')\n",
    "                    user_id, item_id, timestamp = (\n",
    "                        int(user_id), int(item_id), float(timestamp))\n",
    "                    assert user_id % 11 == phase_id\n",
    "                    print(phase_id, user_id, item_id, item_deg[item_id],\n",
    "                          sep=',', file=fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "_create_answer_file_for_evaluation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "current_time: 1591412735\ndate_time: 2020-06-06 11:05:35\ncurrent_phase: 9\n"
    }
   ],
   "source": [
    "result = evaluate('../new_baseline.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'user_id 14997 of phase 4 not in submission'"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.8 64-bit ('ML': conda)",
   "language": "python",
   "name": "python36864bitmlconda22b001fe9e6340f59031359cb65c132c"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}